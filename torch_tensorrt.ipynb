{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, M2M100ForConditionalGeneration, M2M100Tokenizer\n",
    "\n",
    "model_name = \"facebook/wmt21-dense-24-wide-en-x\"\n",
    "model = M2M100ForConditionalGeneration.from_pretrained(model_name)\n",
    "model = model.cuda()\n",
    "model = model.half()\n",
    "model = model.eval()\n",
    "tokenizer = M2M100Tokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/root/.cache/huggingface/datasets/databricks___json/databricks--databricks-dolly-15k-6e0f9ea7eaa0ee08/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 420.31it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import time\n",
    "\n",
    "dataset = load_dataset(\"databricks/databricks-dolly-15k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['instruction', 'context', 'response', 'category'],\n",
       "        num_rows: 15011\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### base translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(model, tokenizer, text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to('cuda')\n",
    "    translated_tokens = model.generate(\n",
    "        **inputs,\n",
    "        forced_bos_token_id=tokenizer.get_lang_id(\"ru\"),\n",
    "        max_new_tokens=1024,\n",
    "    )\n",
    "    result = tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[\n",
    "        0\n",
    "    ]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.696838855743408\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    start = time.time()\n",
    "    fields = [\n",
    "        'instruction', 'context', 'response'\n",
    "    ]\n",
    "    for item in dataset['train'].select(range(5)):\n",
    "        # print(item)\n",
    "        for field in fields:\n",
    "            text = item[field]\n",
    "            result = translate(\n",
    "                model=model,\n",
    "                tokenizer=tokenizer,\n",
    "                text=text\n",
    "            )\n",
    "        # print(result)\n",
    "    print(time.time() - start)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensor rt optimizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1]]]])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 19\u001b[0m\n\u001b[1;32m      4\u001b[0m example[\u001b[39m'\u001b[39m\u001b[39mdecoder_input_ids\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m example[\u001b[39m'\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      6\u001b[0m \u001b[39m# input_ids: Optional[torch.LongTensor] = None,\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39m# attention_mask: Optional[torch.Tensor] = None,\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39m# decoder_input_ids: Optional[torch.LongTensor] = None,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[39m# decoder_inputs_embeds: Optional[torch.FloatTensor] = None,\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[39m# labels: Optional[torch.LongTensor] = None,\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m traced_model \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mjit\u001b[39m.\u001b[39;49mtrace(model, \n\u001b[1;32m     20\u001b[0m \texample_kwarg_inputs\u001b[39m=\u001b[39;49m{\n\u001b[1;32m     21\u001b[0m \t\t\u001b[39m\"\u001b[39;49m\u001b[39minput_ids\u001b[39;49m\u001b[39m\"\u001b[39;49m: torch\u001b[39m.\u001b[39;49mtensor([[\u001b[39m1\u001b[39;49m]]),\n\u001b[1;32m     22\u001b[0m \t\t\u001b[39m\"\u001b[39;49m\u001b[39mattention_mask\u001b[39;49m\u001b[39m\"\u001b[39;49m: torch\u001b[39m.\u001b[39;49mtensor([[\u001b[39m1\u001b[39;49m]]),\n\u001b[1;32m     23\u001b[0m \t\t\u001b[39m\"\u001b[39;49m\u001b[39mdecoder_input_ids\u001b[39;49m\u001b[39m\"\u001b[39;49m: torch\u001b[39m.\u001b[39;49mtensor([[\u001b[39m1\u001b[39;49m]]),\n\u001b[1;32m     24\u001b[0m \t\t\u001b[39m\"\u001b[39;49m\u001b[39mdecoder_attention_mask\u001b[39;49m\u001b[39m\"\u001b[39;49m: torch\u001b[39m.\u001b[39;49mtensor([[\u001b[39m1\u001b[39;49m]]),\n\u001b[1;32m     25\u001b[0m \t\t\u001b[39m\"\u001b[39;49m\u001b[39mhead_mask\u001b[39;49m\u001b[39m\"\u001b[39;49m: torch\u001b[39m.\u001b[39;49mtensor([[\u001b[39m1\u001b[39;49m]]),\n\u001b[1;32m     26\u001b[0m \t\t\u001b[39m\"\u001b[39;49m\u001b[39mdecoder_head_mask\u001b[39;49m\u001b[39m\"\u001b[39;49m: torch\u001b[39m.\u001b[39;49mtensor([[\u001b[39m1\u001b[39;49m]]),\n\u001b[1;32m     27\u001b[0m \t\t\u001b[39m\"\u001b[39;49m\u001b[39mcross_attn_head_mask\u001b[39;49m\u001b[39m\"\u001b[39;49m: torch\u001b[39m.\u001b[39;49mtensor([[\u001b[39m1\u001b[39;49m]]),\n\u001b[1;32m     28\u001b[0m \t\t\u001b[39m\"\u001b[39;49m\u001b[39mencoder_outputs\u001b[39;49m\u001b[39m\"\u001b[39;49m: torch\u001b[39m.\u001b[39;49mtensor([[\u001b[39m1\u001b[39;49m]]),\n\u001b[1;32m     29\u001b[0m \t\t\u001b[39m\"\u001b[39;49m\u001b[39mpast_key_values\u001b[39;49m\u001b[39m\"\u001b[39;49m: torch\u001b[39m.\u001b[39;49mtensor([\n\u001b[1;32m     30\u001b[0m       \t\t[[[\u001b[39m1\u001b[39;49m]]]\n\u001b[1;32m     31\u001b[0m         ]),\n\u001b[1;32m     32\u001b[0m \t\t\u001b[39m\"\u001b[39;49m\u001b[39minputs_embeds\u001b[39;49m\u001b[39m\"\u001b[39;49m: torch\u001b[39m.\u001b[39;49mtensor([[\u001b[39m1\u001b[39;49m]]),\n\u001b[1;32m     33\u001b[0m \t\t\u001b[39m# \"decoder_inputs_embeds\": torch.tensor([[1]]),\u001b[39;49;00m\n\u001b[1;32m     34\u001b[0m \t\t\u001b[39m\"\u001b[39;49m\u001b[39mlabels\u001b[39;49m\u001b[39m\"\u001b[39;49m: torch\u001b[39m.\u001b[39;49mtensor([[\u001b[39m1\u001b[39;49m]]),\n\u001b[1;32m     35\u001b[0m \t},\n\u001b[1;32m     36\u001b[0m  \tstrict\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[1;32m     37\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/jit/_trace.py:794\u001b[0m, in \u001b[0;36mtrace\u001b[0;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit, example_kwarg_inputs, _store_inputs)\u001b[0m\n\u001b[1;32m    792\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    793\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mexample_kwarg_inputs should be a dict\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 794\u001b[0m     \u001b[39mreturn\u001b[39;00m trace_module(\n\u001b[1;32m    795\u001b[0m         func,\n\u001b[1;32m    796\u001b[0m         {\u001b[39m\"\u001b[39;49m\u001b[39mforward\u001b[39;49m\u001b[39m\"\u001b[39;49m: example_inputs},\n\u001b[1;32m    797\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    798\u001b[0m         check_trace,\n\u001b[1;32m    799\u001b[0m         wrap_check_inputs(check_inputs),\n\u001b[1;32m    800\u001b[0m         check_tolerance,\n\u001b[1;32m    801\u001b[0m         strict,\n\u001b[1;32m    802\u001b[0m         _force_outplace,\n\u001b[1;32m    803\u001b[0m         _module_class,\n\u001b[1;32m    804\u001b[0m         example_inputs_is_kwarg\u001b[39m=\u001b[39;49m\u001b[39misinstance\u001b[39;49m(example_kwarg_inputs, \u001b[39mdict\u001b[39;49m),\n\u001b[1;32m    805\u001b[0m         _store_inputs\u001b[39m=\u001b[39;49m_store_inputs\n\u001b[1;32m    806\u001b[0m     )\n\u001b[1;32m    807\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    808\u001b[0m     \u001b[39mhasattr\u001b[39m(func, \u001b[39m\"\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    809\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(func\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m, torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule)\n\u001b[1;32m    810\u001b[0m     \u001b[39mand\u001b[39;00m func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mforward\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    811\u001b[0m ):\n\u001b[1;32m    812\u001b[0m     \u001b[39mif\u001b[39;00m example_inputs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/jit/_trace.py:1044\u001b[0m, in \u001b[0;36mtrace_module\u001b[0;34m(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit, example_inputs_is_kwarg, _store_inputs)\u001b[0m\n\u001b[1;32m   1041\u001b[0m             valid_arguments \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m[\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(argument_names) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1042\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mNameError\u001b[39;00m(\u001b[39m\"\"\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m is not in forward() method\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms arguments,\u001b[39m\n\u001b[1;32m   1043\u001b[0m \u001b[39m             valid arguments name are \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\"\"\u001b[39m\u001b[39m.\u001b[39mformat(key, valid_arguments))\n\u001b[0;32m-> 1044\u001b[0m     module\u001b[39m.\u001b[39;49m_c\u001b[39m.\u001b[39;49m_create_method_from_trace_with_dict(\n\u001b[1;32m   1045\u001b[0m         method_name,\n\u001b[1;32m   1046\u001b[0m         func,\n\u001b[1;32m   1047\u001b[0m         example_inputs,\n\u001b[1;32m   1048\u001b[0m         var_lookup_fn,\n\u001b[1;32m   1049\u001b[0m         strict,\n\u001b[1;32m   1050\u001b[0m         _force_outplace,\n\u001b[1;32m   1051\u001b[0m         argument_names,\n\u001b[1;32m   1052\u001b[0m         _store_inputs\n\u001b[1;32m   1053\u001b[0m     )\n\u001b[1;32m   1054\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1055\u001b[0m     example_inputs \u001b[39m=\u001b[39m make_tuple(example_inputs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1533\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1528\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1529\u001b[0m \u001b[39m# this function, and just call forward.  It's slow for dynamo to guard on the state\u001b[39;00m\n\u001b[1;32m   1530\u001b[0m \u001b[39m# of all these hook dicts individually, so instead it can guard on 2 bools and we just\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[39m# have to promise to keep them up to date when hooks are added or removed via official means.\u001b[39;00m\n\u001b[1;32m   1532\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_hooks \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m _has_global_hooks:\n\u001b[0;32m-> 1533\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1534\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1535\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m         recording_scopes \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1519\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1520\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1521\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m   1522\u001b[0m     \u001b[39mif\u001b[39;00m recording_scopes:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/m2m_100/modeling_m2m_100.py:1335\u001b[0m, in \u001b[0;36mM2M100ForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1330\u001b[0m     \u001b[39mif\u001b[39;00m decoder_input_ids \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1331\u001b[0m         decoder_input_ids \u001b[39m=\u001b[39m shift_tokens_right(\n\u001b[1;32m   1332\u001b[0m             labels, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mpad_token_id, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mdecoder_start_token_id\n\u001b[1;32m   1333\u001b[0m         )\n\u001b[0;32m-> 1335\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\n\u001b[1;32m   1336\u001b[0m     input_ids,\n\u001b[1;32m   1337\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1338\u001b[0m     decoder_input_ids\u001b[39m=\u001b[39;49mdecoder_input_ids,\n\u001b[1;32m   1339\u001b[0m     encoder_outputs\u001b[39m=\u001b[39;49mencoder_outputs,\n\u001b[1;32m   1340\u001b[0m     decoder_attention_mask\u001b[39m=\u001b[39;49mdecoder_attention_mask,\n\u001b[1;32m   1341\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1342\u001b[0m     decoder_head_mask\u001b[39m=\u001b[39;49mdecoder_head_mask,\n\u001b[1;32m   1343\u001b[0m     cross_attn_head_mask\u001b[39m=\u001b[39;49mcross_attn_head_mask,\n\u001b[1;32m   1344\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   1345\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1346\u001b[0m     decoder_inputs_embeds\u001b[39m=\u001b[39;49mdecoder_inputs_embeds,\n\u001b[1;32m   1347\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1348\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1349\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1350\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1351\u001b[0m )\n\u001b[1;32m   1352\u001b[0m lm_logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlm_head(outputs[\u001b[39m0\u001b[39m])\n\u001b[1;32m   1354\u001b[0m masked_lm_loss \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1533\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1528\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1529\u001b[0m \u001b[39m# this function, and just call forward.  It's slow for dynamo to guard on the state\u001b[39;00m\n\u001b[1;32m   1530\u001b[0m \u001b[39m# of all these hook dicts individually, so instead it can guard on 2 bools and we just\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[39m# have to promise to keep them up to date when hooks are added or removed via official means.\u001b[39;00m\n\u001b[1;32m   1532\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_hooks \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m _has_global_hooks:\n\u001b[0;32m-> 1533\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1534\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1535\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m         recording_scopes \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1519\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1520\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1521\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m   1522\u001b[0m     \u001b[39mif\u001b[39;00m recording_scopes:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/m2m_100/modeling_m2m_100.py:1226\u001b[0m, in \u001b[0;36mM2M100Model.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1219\u001b[0m     encoder_outputs \u001b[39m=\u001b[39m BaseModelOutput(\n\u001b[1;32m   1220\u001b[0m         last_hidden_state\u001b[39m=\u001b[39mencoder_outputs[\u001b[39m0\u001b[39m],\n\u001b[1;32m   1221\u001b[0m         hidden_states\u001b[39m=\u001b[39mencoder_outputs[\u001b[39m1\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(encoder_outputs) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1222\u001b[0m         attentions\u001b[39m=\u001b[39mencoder_outputs[\u001b[39m2\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(encoder_outputs) \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1223\u001b[0m     )\n\u001b[1;32m   1225\u001b[0m \u001b[39m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1226\u001b[0m decoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(\n\u001b[1;32m   1227\u001b[0m     input_ids\u001b[39m=\u001b[39;49mdecoder_input_ids,\n\u001b[1;32m   1228\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mdecoder_attention_mask,\n\u001b[1;32m   1229\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_outputs[\u001b[39m0\u001b[39;49m],\n\u001b[1;32m   1230\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1231\u001b[0m     head_mask\u001b[39m=\u001b[39;49mdecoder_head_mask,\n\u001b[1;32m   1232\u001b[0m     cross_attn_head_mask\u001b[39m=\u001b[39;49mcross_attn_head_mask,\n\u001b[1;32m   1233\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   1234\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49mdecoder_inputs_embeds,\n\u001b[1;32m   1235\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1236\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1237\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1238\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1239\u001b[0m )\n\u001b[1;32m   1241\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m return_dict:\n\u001b[1;32m   1242\u001b[0m     \u001b[39mreturn\u001b[39;00m decoder_outputs \u001b[39m+\u001b[39m encoder_outputs\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1533\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1528\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1529\u001b[0m \u001b[39m# this function, and just call forward.  It's slow for dynamo to guard on the state\u001b[39;00m\n\u001b[1;32m   1530\u001b[0m \u001b[39m# of all these hook dicts individually, so instead it can guard on 2 bools and we just\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[39m# have to promise to keep them up to date when hooks are added or removed via official means.\u001b[39;00m\n\u001b[1;32m   1532\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_hooks \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m _has_global_hooks:\n\u001b[0;32m-> 1533\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1534\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1535\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m         recording_scopes \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1519\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1520\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1521\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m   1522\u001b[0m     \u001b[39mif\u001b[39;00m recording_scopes:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/m2m_100/modeling_m2m_100.py:997\u001b[0m, in \u001b[0;36mM2M100Decoder.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    995\u001b[0m \u001b[39mprint\u001b[39m(past_key_values)\n\u001b[1;32m    996\u001b[0m \u001b[39m# past_key_values_length\u001b[39;00m\n\u001b[0;32m--> 997\u001b[0m past_key_values_length \u001b[39m=\u001b[39m past_key_values[\u001b[39m0\u001b[39;49m][\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mshape[\u001b[39m2\u001b[39;49m] \u001b[39mif\u001b[39;00m past_key_values \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[1;32m    999\u001b[0m \u001b[39mif\u001b[39;00m inputs_embeds \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1000\u001b[0m     inputs_embeds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_tokens(input_ids) \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_scale\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "example = tokenizer(\"hello world\", return_tensors='pt').to('cuda')\n",
    "example['decoder_input_ids'] = example['input_ids']\n",
    "\n",
    "# input_ids: Optional[torch.LongTensor] = None,\n",
    "# attention_mask: Optional[torch.Tensor] = None,\n",
    "# decoder_input_ids: Optional[torch.LongTensor] = None,\n",
    "# decoder_attention_mask: Optional[torch.LongTensor] = None,\n",
    "# head_mask: Optional[torch.Tensor] = None,\n",
    "# decoder_head_mask: Optional[torch.Tensor] = None,\n",
    "# cross_attn_head_mask: Optional[torch.Tensor] = None,\n",
    "# encoder_outputs: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
    "# past_key_values: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
    "# inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "# decoder_inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "# labels: Optional[torch.LongTensor] = None,\n",
    "\n",
    "traced_model = torch.jit.trace(model, \n",
    "\texample_kwarg_inputs={\n",
    "\t\t\"input_ids\": torch.tensor([[1]]),\n",
    "\t\t\"attention_mask\": torch.tensor([[1]]),\n",
    "\t\t\"decoder_input_ids\": torch.tensor([[1]]),\n",
    "\t\t\"decoder_attention_mask\": torch.tensor([[1]]),\n",
    "\t\t\"head_mask\": torch.tensor([[1]]),\n",
    "\t\t\"decoder_head_mask\": torch.tensor([[1]]),\n",
    "\t\t\"cross_attn_head_mask\": torch.tensor([[1]]),\n",
    "\t\t\"encoder_outputs\": torch.tensor([[1]]),\n",
    "\t\t\"past_key_values\": torch.tensor([\n",
    "      \t\t[[[1]]]\n",
    "        ]),\n",
    "\t\t\"inputs_embeds\": torch.tensor([[1]]),\n",
    "\t\t# \"decoder_inputs_embeds\": torch.tensor([[1]]),\n",
    "\t\t\"labels\": torch.tensor([[1]]),\n",
    "\t},\n",
    " \tstrict=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [128001, 97394, 1211, 2],\n",
       " 'attention_mask': [1, 1, 1, 1],\n",
       " 'decoder_input_ids': [128001, 97394, 1211, 2]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[[1]]][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Found Tensor and Tuple[Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor]]\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
